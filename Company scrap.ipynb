{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time, sys\n",
    "import requests as r\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(\"driver/chromedriver.exe\")\n",
    "browser.maximize_window()\n",
    "browser.get(\"https://linkedin.com/uas/login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('config.txt')\n",
    "line = file.readlines()\n",
    "username = line[0]\n",
    "password = line[1]\n",
    "\n",
    "elementID = browser.find_element_by_id('username') #use view source code to check ID of username\n",
    "passwordID = browser.find_element_by_id('password')\n",
    "\n",
    "elementID.send_keys(username)\n",
    "passwordID.send_keys(password)\n",
    "\n",
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:/Users/Admin/Documents/Keshav/Excel/Industry_n1.csv').dropna()\n",
    "name = [list(df.items())[0][1][i] for i in range(df.shape[0])]\n",
    "# last = [list(df.items())[1][1][i] for i in range(df.shape[0])]\n",
    "# Country = [list(df.items())[2][1][i] for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def company_title_add_sales_navigator(n,l,i):\n",
    "#         try:\n",
    "#             if i !=2:\n",
    "#                 time.sleep(3)\n",
    "#                 browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[11]/div/div/ul/li/div[2]/button\").click()\n",
    "#                 time.sleep(3)\n",
    "#                 browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[6]/div/div/ul/li/div[2]/button\").click()\n",
    "#             browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[11]/div/div/div/div/button\").click()\n",
    "#             browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[11]/div/div/div[3]/input\").send_keys(l)\n",
    "#             browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[11]/div/div/div[3]/input\").send_keys(Keys.ENTER)\n",
    "#             time.sleep(4)\n",
    "#             browser.find_element_by_xpath(\"//div[@id='ember73']//div[@class = 'flex pt4 ph4 pb3 flex-wrap cursor-pointer']\").click()\n",
    "#             browser.find_element_by_xpath(\"//div[@id='ember72']//div[@class = 'ph4 pb4']//input[@id = 'ember72-typeahead']\").send_keys(n)\n",
    "#             time.sleep(3)\n",
    "#             t = browser.find_elements_by_xpath('//*[@id=\"ember72\"]/div[3]/ol/li')\n",
    "#             m = [browser.find_element_by_xpath(f'//*[@id=\"ember72\"]/div[3]/ol/li[{i+1}]/button').get_attribute(\"title\").lower() for i in range(len(t))]\n",
    "#             for i,j in enumerate(m):\n",
    "#                 if n.lower() == j.lower():\n",
    "#                     browser.find_element_by_xpath(f'//*[@id=\"ember72\"]/div[3]/ol/li[{i+1}]/button').click()\n",
    "#                     return 1\n",
    "#                     break\n",
    "#             for i,j in enumerate(m):\n",
    "#                 if n.lower() in j.lower():\n",
    "#                     browser.find_element_by_xpath(f'//*[@id=\"ember72\"]/div[3]/ol/li[{i+1}]/button').click()\n",
    "#                     return 2\n",
    "#                     break\n",
    "#             browser.find_element_by_xpath(\"//div[@id='ember72']//div[@class = 'ph4 pb4']//input[@id = 'ember72-typeahead']\").send_keys(Keys.ENTER)\n",
    "#             return [n,l]\n",
    "#         except:\n",
    "#             browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[11]/div/div/div[3]/input\").clear()\n",
    "#             browser.find_element_by_xpath(\"//div[@id='ember72']//div[@class = 'ph4 pb4']//input[@id = 'ember72-typeahead']\").clear()\n",
    "#             return [n,l]\n",
    "\n",
    "\n",
    "# browser.get('https://www.linkedin.com/sales/search/people')\n",
    "# for i in range(2,len(name)):\n",
    "#     n = name[i]\n",
    "#     l = last[i]\n",
    "# #     c = Country[i]\n",
    "#     print(company_title_add_sales_navigator(n,l,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser.get('https://www.linkedin.com/sales/search/people?doFetchHeroCard=false&firstName=Rajan%20&lastName=Anandan&logHistory=true&page=1&rsLogId=910627841&searchSessionId=X%2F4wls68QpyzKa3MCyKfRw%3D%3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(559,len(name)): \n",
    "#     browser.find_element_by_xpath('/html/body/main/div[1]/form/ul/li[12]/div/div/div/div/button').click()\n",
    "#     browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[12]/div/div/div[2]/input\").clear()\n",
    "#     browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[12]/div/div/div[2]/input\").send_keys(name[i])\n",
    "#     browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[12]/div/div/div[2]/input\").send_keys(Keys.ENTER)\n",
    "#     browser.find_element_by_xpath('/html/body/main/div[1]/form/ul/li[13]/div/div/div/div/button').click()\n",
    "#     browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[13]/div/div/div[2]/input\").clear()\n",
    "#     browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[13]/div/div/div[2]/input\").send_keys(last[i])\n",
    "#     browser.find_element_by_xpath(\"/html/body/main/div[1]/form/ul/li[13]/div/div/div[2]/input\").send_keys(Keys.ENTER)\n",
    "\n",
    "#     time.sleep(15)\n",
    "#     print(i)\n",
    "#     browser.find_element_by_xpath('/html/body/main/div[1]/div/section/div[1]/div[1]/ol/li[1]/div[2]/div/div/div/article/section[1]/div[2]/div/div/span/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def company_add_sales_navigator(n):\n",
    "#         try:\n",
    "#             browser.find_element_by_xpath(\"//div[@id='ember72']//div[@class = 'ph4 pb4']//input[@id = 'ember72-typeahead']\").send_keys(n)\n",
    "#             time.sleep(3)\n",
    "#             t = browser.find_elements_by_xpath('//*[@id=\"ember72\"]/div[3]/ol/li')\n",
    "#             m = [browser.find_element_by_xpath(f'//*[@id=\"ember72\"]/div[3]/ol/li[{i+1}]/button').get_attribute(\"title\").lower() for i in range(len(t))]\n",
    "#             for i,j in enumerate(m):\n",
    "#                 if n.lower() == j.lower():\n",
    "#                     browser.find_element_by_xpath(f'//*[@id=\"ember72\"]/div[3]/ol/li[{i+1}]/button').click()\n",
    "#                     return 1\n",
    "#                     break\n",
    "#             for i,j in enumerate(m):\n",
    "#                 if n.lower() in j.lower():\n",
    "#                     browser.find_element_by_xpath(f'//*[@id=\"ember72\"]/div[3]/ol/li[{i+1}]/button').click()\n",
    "#                     return 2\n",
    "#                     break\n",
    "#             browser.find_element_by_xpath(\"//div[@id='ember72']//div[@class = 'ph4 pb4']//input[@id = 'ember72-typeahead']\").send_keys(Keys.ENTER)\n",
    "#             return n\n",
    "#         except:\n",
    "#             browser.find_element_by_xpath(\"//div[@id='ember72']//div[@class = 'ph4 pb4']//input[@id = 'ember72-typeahead']\").clear()\n",
    "#             return n\n",
    "\n",
    "\n",
    "# browser.get('https://www.linkedin.com/sales/search/people')\n",
    "# browser.find_element_by_xpath(\"//div[@id='ember73']//div[@class = 'flex pt4 ph4 pb3 flex-wrap cursor-pointer']\").click()\n",
    "# m = browser.find_elements_by_tag_name('button')\n",
    "# for i in range(len(name)):\n",
    "#     n = name[i]\n",
    "#     print(company_add_sales_navigator(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Weblink\n",
    "# for i in range(len(name)):\n",
    "#     browser.get(\"https://google.com\")\n",
    "#     browser.find_element_by_xpath('/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input').send_keys(name[i])\n",
    "#     browser.find_element_by_xpath('/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input').submit()\n",
    "# #     time.sleep(3)\n",
    "#     try:\n",
    "#         a = browser.find_element_by_class_name('yuRUbf')\n",
    "#         b = a.find_element_by_xpath(\".//*\").get_attribute(\"href\")\n",
    "#         print(b)\n",
    "    \n",
    "#     except:\n",
    "#         print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_state(soup):\n",
    "#     try:\n",
    "#         main = soup.find_all('div',{'class':'pb2'})\n",
    "#         for i in main:\n",
    "#             link = i.find('span',{'class':'text-body-small inline t-black--light break-words'})\n",
    "#             return link.get_text().strip().split(\",\")[0]\n",
    "#     except:\n",
    "#         return 0\n",
    "# for i in range(len(name)):\n",
    "#     link = name[i]\n",
    "#     browser.get(link)\n",
    "#     out = get_state(BeautifulSoup(browser.page_source))\n",
    "#     print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "# def get_industry(soup,name):\n",
    "#     try:\n",
    "#         industry = soup.find('div',{'class':\"entity-result__primary-subtitle t-14 t-black\"})\n",
    "#         final = industry.text.split(\" â€¢ \")\n",
    "#         indus = soup.find('div',{'class':\"ph0 pv2 artdeco-card mb2\"})\n",
    "#         main = indus.find_all('div',{'class':'t-roman t-sans'})\n",
    "#         for i in main:\n",
    "#             link = i.find('a',{'class':'app-aware-link'})\n",
    "#             a = link.get_text().strip().lower()\n",
    "#             b = name.lower()\n",
    "#             if a == b:\n",
    "#                 return final[0].strip()\n",
    "#     except:\n",
    "#         return 0\n",
    "# for i in range(len(name)):\n",
    "#     full_link = \"https://www.linkedin.com/search/results/companies/?keywords=\" + name[i]\n",
    "#     browser.get(full_link)\n",
    "#     out = get_industry(BeautifulSoup(browser.page_source),name[i])\n",
    "#     print(out)\n",
    "# t2 = time.time()\n",
    "# print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "# def get_industry(soup,name):\n",
    "#     try:\n",
    "#         industry = soup.find('div',{'class':\"ph0 pv2 artdeco-card mb2\"})\n",
    "#         main = industry.find_all('div',{'class':'t-roman t-sans'})\n",
    "#         for i in main:\n",
    "#             link = i.find('a',{'class':'app-aware-link'})\n",
    "#             if name == link.get_text().strip():\n",
    "#                 browser.get(link.get('href'))\n",
    "#                 content = browser.page_source.encode('utf-8').strip()\n",
    "#                 soups = BeautifulSoup(content,\"html.parser\")\n",
    "#                 about = soups.find_all('li',{'class':'org-page-navigation__item m0'})\n",
    "#                 about_link = 'https://www.linkedin.com' + about[1].find('a').get('href')\n",
    "#                 browser.get(about_link)\n",
    "#                 content2 = browser.page_source.encode('utf-8').strip()\n",
    "#                 soup2 = BeautifulSoup(content2,\"html.parser\")\n",
    "#                 key = soup2.find_all('dt',class_='org-page-details__definition-term t-14 t-black t-bold')\n",
    "#                 for i in key:\n",
    "#                     if i.get_text().strip().lower() == \"industry\":\n",
    "#                         value1 = i.find_next('dd',class_='org-page-details__definition-text t-14 t-black--light t-normal').get_text().strip()\n",
    "# #                     if i.get_text().strip().lower() == \"company size\":\n",
    "# #                         value2 = i.find_next('dd',class_='org-about-company-module__company-size-definition-text t-14 t-black--light mb1 fl').get_text().strip()\n",
    "#                         return value1\n",
    "#     except:\n",
    "#         return 0\n",
    "# for i in range(len(name)):\n",
    "#     full_link = \"https://www.linkedin.com/search/results/companies/?keywords=\" + name[i]\n",
    "#     browser.get(full_link)\n",
    "#     out = get_industry(BeautifulSoup(browser.page_source),name[i])\n",
    "#     print(out)\n",
    "# t2 = time.time()\n",
    "# print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "# def get_industry_sales(name):\n",
    "#     try:\n",
    "#         inputs = browser.find_element_by_id(\"global-typeahead-search-input\")\n",
    "#         inputs.send_keys(name)\n",
    "#         browser.find_element_by_xpath('/html/body/header/div/div[2]/section/div/div[1]/div/div/div[2]/button[2]').click()\n",
    "#         time.sleep(3)\n",
    "#         company = browser.find_element_by_class_name('hero-card__sub-content-item').text\n",
    "#         return company\n",
    "#     except:\n",
    "#         return 0\n",
    "# for i in range(len(name)):\n",
    "#     full_link = \"https://www.linkedin.com/sales/search/company\"\n",
    "#     browser.get(full_link)\n",
    "#     out = get_industry_sales(name[i])\n",
    "#     print(out)\n",
    "# t2 = time.time()\n",
    "# print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support.expected_conditions import presence_of_element_located\n",
    "# import time\n",
    "# import sys\n",
    "\n",
    "# url = 'https://www.linkedin.com/in/ACwAAACQrAwBsa4IxvkcySdP-Nh-1MCUG6J12-M/'\n",
    "# chrome_driver_path = 'driver/chromedriver.exe'\n",
    "\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument('--headless')\n",
    "\n",
    "# webdriver = webdriver.Chrome(\n",
    "#   executable_path=chrome_driver_path, options=chrome_options\n",
    "# )\n",
    "\n",
    "# # default search query\n",
    "# search_query = \"life\"\n",
    "\n",
    "# # if (len(sys.argv) >= 2):\n",
    "# #     search_query = sys.argv[1]\n",
    "# #     print(search_query)\n",
    "\n",
    "\n",
    "# with webdriver as driver:\n",
    "#     # Set timeout time \n",
    "#     wait = WebDriverWait(driver, 10)\n",
    "\n",
    "#     # retrive url in headless browser\n",
    "#     driver.get(url)\n",
    "    \n",
    "#     # find search box\n",
    "# #     search = driver.find_element_by_id(\"hmSearch\")\n",
    "# #     search.send_keys(search_query + Keys.RETURN)\n",
    "    \n",
    "# #     wait.until(presence_of_element_located((By.ID, \"quotesList\")))\n",
    "\n",
    "#     results = driver.find_element_by_class_name('experience-section')\n",
    "#     print(results)\n",
    "# #     for quote in results:\n",
    "# #         quoteArr = quote.text.split('\\n')\n",
    "# #         print(quoteArr)\n",
    "# #         print()\n",
    "\n",
    "#     # must close the driver after task finished\n",
    "#     driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = time.time() \n",
    "# def get_link_name_company_matches(soup,name):\n",
    "#     try:\n",
    "# #         main = soup.find_all('div',{'class':'t-roman t-sans'})\n",
    "# #         fname = name.split(\"_\")[0]\n",
    "# #         lname = name.split(\"_\")[1]\n",
    "# #         cname = name.split(\"_\")[-1]\n",
    "# #         for i in main:\n",
    "# #             link = i.find('a',{'class':'app-aware-link'})\n",
    "# #             full_name = link.find(\"span\",{'aria-hidden':\"true\"}).get_text().strip()\n",
    "# #             if fname in full_name and lname in full_name:\n",
    "# #                 browser.get(link.get('href'))\n",
    "# #                 soup2 = BeautifulSoup(browser.page_source)\n",
    "# #                 current_company = soup2.find('div',{'aria-label':\"Current company\"}).get_text().strip()\n",
    "# #                 print(name.split(\"_\"))\n",
    "# #                 k = browser.find_element_by_class_name('pv-entity__secondary-title t-14 t-black t-normal')\n",
    "# #                 print(k)\n",
    "# #                 all_c = soup2.find('div',class_='display-flex flex-column full-width')\n",
    "# #                 print(all_c)\n",
    "# #                 all_company = all_c.find_all('p',class_='pv-entity__secondary-title t-14 t-black t-normal')\n",
    "# #                 print(all_company)\n",
    "# #                 if cname.lower() in current_company.lower():\n",
    "# #                         print(current_company)\n",
    "# #                         return link.get('href')\n",
    "# #                 else:\n",
    "# #                     for company in all_company:\n",
    "# #                         company_name = company.get_text().strip()\n",
    "# #                         print(company_name)\n",
    "# #                         if cname.lower() in company_name.lower():\n",
    "# #                             print(company_name)\n",
    "# #                             return link.get('href')\n",
    "# #                             break\n",
    "#         print(a)\n",
    "#     except:\n",
    "#         main = soup.find_all('div',{'class':'t-roman t-sans'})\n",
    "#         fname = name.split(\"_\")[0]\n",
    "#         lname = name.split(\"_\")[1]\n",
    "#         cname = name.split(\"_\")[-1]\n",
    "#         for i in main:\n",
    "#             link = i.find('a',{'class':'app-aware-link'})\n",
    "#             full_name = link.find(\"span\",{'aria-hidden':\"true\"}).get_text().strip()\n",
    "#             if fname in full_name and lname in full_name:\n",
    "#                 browser.get(link.get('href'))\n",
    "#                 soup2 = BeautifulSoup(browser.page_source)\n",
    "#                 current_company = soup2.find('div',{'aria-label':\"Current company\"}).get_text().strip()\n",
    "#                 print(name.split(\"_\"))\n",
    "#                 browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "#                 time.sleep(7)\n",
    "#                 k = browser.find_element_by_xpath(\"//div\")\n",
    "#                 print(k,1)\n",
    "#                 all_c = soup2.find('div',class_='display-flex flex-column full-width')\n",
    "#                 print(all_c,2)\n",
    "#                 all_company = soup2.find_all('p',class_='pv-entity__secondary-title t-14 t-black t-normal')\n",
    "#                 print(all_company,3)\n",
    "#                 if cname.lower() not in current_company.lower():\n",
    "#                         print(current_company)\n",
    "#                         return link.get('href')\n",
    "#                 else:\n",
    "#                     for company in all_company:\n",
    "#                         company_name = company.get_text().strip()\n",
    "#                         print(company_name)\n",
    "#                         if cname.lower() in company_name.lower():\n",
    "#                             print(company_name)\n",
    "#                             return link.get('href')\n",
    "#                             break\n",
    "#         return 0\n",
    "    \n",
    "# for i in range(len(name)):\n",
    "#     full_link = \"https://www.linkedin.com/search/results/all/?keywords=\" + name[i]\n",
    "#     browser.get(full_link)\n",
    "#     out = get_link_name_company_matches(BeautifulSoup(browser.page_source),name[i])\n",
    "#     print(out)\n",
    "# t2 = time.time()\n",
    "# print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "# def get_link_name_matches(soup,name):\n",
    "#     try:\n",
    "#         main = soup.find_all('div',{'class':'t-roman t-sans'})\n",
    "#         fname = name.split()[0]\n",
    "#         lname = name.split()[1]\n",
    "#         for i in main:\n",
    "#             link = i.find('a',{'class':'app-aware-link'})\n",
    "#             full_name = link.find(\"span\",{'aria-hidden':\"true\"}).get_text().strip()\n",
    "#             if fname in full_name and lname in full_name:\n",
    "#                 return link.get('href')\n",
    "#     except:\n",
    "#         return 0\n",
    "    \n",
    "# for i in range(len(name)):\n",
    "#     full_link = \"https://www.linkedin.com/search/results/all/?keywords=\" + name[i]\n",
    "#     browser.get(full_link)\n",
    "#     out = get_link_name_matches(BeautifulSoup(browser.page_source),name[i])\n",
    "#     print(out)\n",
    "# t2 = time.time()\n",
    "# print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "# def get_link(soup,name):\n",
    "#     try:\n",
    "# #         industry = soup.find('div',{'class':\"t-roman t-sans\"})\n",
    "# #         final = industry.text\n",
    "# #         print(final.split())\n",
    "#         main = soup.find_all('div',{'class':'t-roman t-sans'})\n",
    "#         for i in main:\n",
    "#             link = i.find('a',{'class':'app-aware-link'})\n",
    "#             return link.get('href')\n",
    "#     except:\n",
    "#         return 0\n",
    "# for i in range(len(name)):\n",
    "#     full_link = \"https://www.linkedin.com/search/results/all/?keywords=\" + name[i]\n",
    "#     browser.get(full_link)\n",
    "# #     time.sleep(5)\n",
    "#     out = get_link(BeautifulSoup(browser.page_source),name[i])\n",
    "#     print(out)\n",
    "# t2 = time.time()\n",
    "# print(t2-t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
